# Chatbot App con WebUI y Ollama (Usando Docker) ğŸ¤–ğŸš€

Este proyecto implementa una aplicaciÃ³n de chatbot local utilizando WebUI y Ollama. La configuraciÃ³n se realiza completamente en contenedores Docker, lo que asegura un entorno limpio, reproducible y fÃ¡cil de desplegar.

## ğŸŒŸ CaracterÃ­sticas

â€¢	ğŸ¤– Chatbot basado en LLMs: InteractÃºa con modelos avanzados de lenguaje.
â€¢	ğŸ’» WebUI intuitiva: Interfaz grÃ¡fica para facilitar la interacciÃ³n.
â€¢	ğŸ”’ Despliegue local: Toda la aplicaciÃ³n se ejecuta en tu mÃ¡quina, garantizando privacidad.
â€¢	ğŸ³ Aislamiento con Docker: ConfiguraciÃ³n y ejecuciÃ³n simplificada.

## ğŸ› ï¸ Requisitos previos

1.	Docker instalado en tu mÃ¡quina.
â€¢	Descarga e instala Docker desde: https://www.docker.com/get-started
2.	Git para clonar el repositorio.
â€¢	InstÃ¡lalo desde: https://git-scm.com/

## ğŸš€ InstalaciÃ³n y configuraciÃ³n

1. Clona este repositorio:  
```plaintext
git clone https://github.com/tu-usuario/chatbot-docker-app.git
cd chatbot-docker-app
```

2.	Inicia los contenedores:
```plaintext
docker-compose up -d
```

3.	Accede a la aplicaciÃ³n:
â€¢	Abre tu navegador y ve a: http://localhost:3000

4.	Para los contenedores:
```plaintext
docker-compose down
```

## ğŸ“‚ Estructura del proyecto

```plaintext
chatbot-docker-app/
â”œâ”€â”€ docker-compose.yml          # ConfiguraciÃ³n de mÃºltiples servicios
â”œâ”€â”€ backend/                    # Volumen con backend de WebUI
â”‚   â””â”€â”€ vector_db/              # DB de vectores y conversaciones
â”œâ”€â”€ models/                     # Volumen con modelos de Ollama
â”‚   â”œâ”€â”€ blobs/                  # Archivos estÃ¡ticos de la WebUI
â”‚   â””â”€â”€ manifests/              # Servidor principal (Flask/FastAPI)
â””â”€â”€ README.md                   # Este archivo
```
